<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>该死的秋招 • Posts by &#34;kafka&#34; tag</title>
        <link>http://example.com</link>
        <description>孵化中···</description>
        <language>zh-CN</language>
        <pubDate>Thu, 12 Oct 2023 21:06:00 +0800</pubDate>
        <lastBuildDate>Thu, 12 Oct 2023 21:06:00 +0800</lastBuildDate>
        <category>hello blog</category>
        <category>设计模式</category>
        <category>MySQL</category>
        <category>算法</category>
        <category>Redis</category>
        <category>其他</category>
        <category>分布式</category>
        <category>数据结构</category>
        <category>Spring</category>
        <category>Thread</category>
        <category>Java</category>
        <category>JDK</category>
        <category>SQL</category>
        <category>JVM</category>
        <category>多线程</category>
        <category>kafka</category>
        <category>SpringBoot</category>
        <category>JUC相关零碎知识点乱写</category>
        <category>hashmap</category>
        <category>JUC</category>
        <category>redis</category>
        <category>springboot</category>
        <item>
            <guid isPermalink="true">http://example.com/2023/10/12/kafka%E7%9B%B8%E5%85%B3/</guid>
            <title>kafka相关</title>
            <link>http://example.com/2023/10/12/kafka%E7%9B%B8%E5%85%B3/</link>
            <category>kafka</category>
            <pubDate>Thu, 12 Oct 2023 21:06:00 +0800</pubDate>
            <description><![CDATA[ &lt;h3 id=&#34;写在前面&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#写在前面&#34;&gt;#&lt;/a&gt; 写在前面&lt;/h3&gt;
&lt;p&gt;对于 kafka，没有使用经验，但是有的面试会问到，水也深，只能记一些理解的&lt;br&gt;
先上图：&lt;br&gt;
&lt;img data-src=&#34;https://pic.imgdb.cn/item/6527f038c458853aef7b1fa7.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;构成&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#构成&#34;&gt;#&lt;/a&gt; 构成&lt;/h3&gt;
&lt;p&gt;简单聊一下构成，直接从大的来说，一个 kafka 服务器被称作一个 broker，若干个 broker 组成 kafka 集群；对于内部来说，broker 由若干个 topic 组成，每个 topic 包括若干个 partition，对于消费者来说，可以消费不同的 partition，所以可以支持批量消费，但是对于一个 partition 来说，消费者不能重复消费。&lt;/p&gt;
&lt;h3 id=&#34;如何保证消费的有序&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#如何保证消费的有序&#34;&gt;#&lt;/a&gt; 如何保证消费的有序&lt;/h3&gt;
&lt;p&gt;kafka 的 partition 中消息的存入是有序的，也就是链表的形式，所以要保证消费的有序，那么生产要生产到指定的分区，并且消费也针对具体的分区；或者就是只使用一个 partition。&lt;/p&gt;
&lt;h3 id=&#34;如何防止重复消费&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#如何防止重复消费&#34;&gt;#&lt;/a&gt; 如何防止重复消费&lt;/h3&gt;
&lt;p&gt;如果参数设置 auto-commit 为 true 的话，那么 offset 可能会提交不成功，那么就会导致重复消费；所以如果要防止重复消费，这个参数要设置成 false，具体的实现应该是 consumer 自主控制 offset。&lt;/p&gt;
&lt;h3 id=&#34;如何保证消息不丢失&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#如何保证消息不丢失&#34;&gt;#&lt;/a&gt; 如何保证消息不丢失&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80NTk2MTA0MTg=&#34;&gt;https://zhuanlan.zhihu.com/p/459610418&lt;/span&gt;&lt;br&gt;
 这篇写挺好的&lt;br&gt;
从三个方面来回答，producer 端，选用的同步策略默认是 1 对接 leader broker；0 发完就完事；all -1 等待所有的 follower；如果要保证发送端不丢的话就尽量增加接收的 follower 数，并且也要设置淘汰队列的最小数，也就是长时间未同步的副本会被踢出同步队列，这样全部踢完的话，那么 producer 端对接的 leader 挂掉的话，就会产生消息丢失了。&lt;/p&gt;
&lt;p&gt;broker 端，应为采用的页缓存，也就是 cpu 缓存，并且刷盘的策略是由操作系统完成的，所以这个时候就是会产生 broker 端挂掉，但是数据没刷盘的情况，所以保证 broker 端数据不丢的话，还是就是副本多完事&lt;/p&gt;
&lt;p&gt;consumer 端，导致的原因就是 offset 了，自动提交的话会导致业务挂了，但是 offset 后移了，那么就是消息丢失了，所以为了保证不丢，那么最好关掉 offset，并且先执行逻辑，然后提交 offset，这样就会出现重复消费的情况，那么可以选择加入幂等策略。&lt;/p&gt;
&lt;h3 id=&#34;如何实现高效读写的&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#如何实现高效读写的&#34;&gt;#&lt;/a&gt; 如何实现高效读写的&lt;/h3&gt;
&lt;p&gt;页缓存 page cache（操作系统级的缓存） + 顺序写（通过末尾追加的方式写入数据） + 零拷贝（如果不做任何处理就是磁盘 - os cache - 应用缓存 - socket 缓存 - 网卡发送） 零拷贝就去掉了冗余的拷贝过程，直接让 socket 与网卡交互，socket 缓存了数据的描述，具体的数据直接通过 os cache 发送给网卡&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>
