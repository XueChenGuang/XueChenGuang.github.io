{
    "version": "https://jsonfeed.org/version/1",
    "title": "该死的秋招 • All posts by \"kafka\" tag",
    "description": "孵化中···",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2023/10/12/kafka%E7%9B%B8%E5%85%B3/",
            "url": "http://example.com/2023/10/12/kafka%E7%9B%B8%E5%85%B3/",
            "title": "kafka相关",
            "date_published": "2023-10-12T13:06:00.000Z",
            "content_html": "<h3 id=\"写在前面\"><a class=\"markdownIt-Anchor\" href=\"#写在前面\">#</a> 写在前面</h3>\n<p>对于 kafka，没有使用经验，但是有的面试会问到，水也深，只能记一些理解的<br>\n先上图：<br>\n<img data-src=\"https://pic.imgdb.cn/item/6527f038c458853aef7b1fa7.jpg\" alt=\"\"></p>\n<h3 id=\"构成\"><a class=\"markdownIt-Anchor\" href=\"#构成\">#</a> 构成</h3>\n<p>简单聊一下构成，直接从大的来说，一个 kafka 服务器被称作一个 broker，若干个 broker 组成 kafka 集群；对于内部来说，broker 由若干个 topic 组成，每个 topic 包括若干个 partition，对于消费者来说，可以消费不同的 partition，所以可以支持批量消费，但是对于一个 partition 来说，消费者不能重复消费。</p>\n<h3 id=\"如何保证消费的有序\"><a class=\"markdownIt-Anchor\" href=\"#如何保证消费的有序\">#</a> 如何保证消费的有序</h3>\n<p>kafka 的 partition 中消息的存入是有序的，也就是链表的形式，所以要保证消费的有序，那么生产要生产到指定的分区，并且消费也针对具体的分区；或者就是只使用一个 partition。</p>\n<h3 id=\"如何防止重复消费\"><a class=\"markdownIt-Anchor\" href=\"#如何防止重复消费\">#</a> 如何防止重复消费</h3>\n<p>如果参数设置 auto-commit 为 true 的话，那么 offset 可能会提交不成功，那么就会导致重复消费；所以如果要防止重复消费，这个参数要设置成 false，具体的实现应该是 consumer 自主控制 offset。</p>\n<h3 id=\"如何保证消息不丢失\"><a class=\"markdownIt-Anchor\" href=\"#如何保证消息不丢失\">#</a> 如何保证消息不丢失</h3>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80NTk2MTA0MTg=\">https://zhuanlan.zhihu.com/p/459610418</span><br>\n 这篇写挺好的<br>\n从三个方面来回答，producer 端，选用的同步策略默认是 1 对接 leader broker；0 发完就完事；all -1 等待所有的 follower；如果要保证发送端不丢的话就尽量增加接收的 follower 数，并且也要设置淘汰队列的最小数，也就是长时间未同步的副本会被踢出同步队列，这样全部踢完的话，那么 producer 端对接的 leader 挂掉的话，就会产生消息丢失了。</p>\n<p>broker 端，应为采用的页缓存，也就是 cpu 缓存，并且刷盘的策略是由操作系统完成的，所以这个时候就是会产生 broker 端挂掉，但是数据没刷盘的情况，所以保证 broker 端数据不丢的话，还是就是副本多完事</p>\n<p>consumer 端，导致的原因就是 offset 了，自动提交的话会导致业务挂了，但是 offset 后移了，那么就是消息丢失了，所以为了保证不丢，那么最好关掉 offset，并且先执行逻辑，然后提交 offset，这样就会出现重复消费的情况，那么可以选择加入幂等策略。</p>\n<h3 id=\"如何实现高效读写的\"><a class=\"markdownIt-Anchor\" href=\"#如何实现高效读写的\">#</a> 如何实现高效读写的</h3>\n<p>页缓存 page cache（操作系统级的缓存） + 顺序写（通过末尾追加的方式写入数据） + 零拷贝（如果不做任何处理就是磁盘 - os cache - 应用缓存 - socket 缓存 - 网卡发送） 零拷贝就去掉了冗余的拷贝过程，直接让 socket 与网卡交互，socket 缓存了数据的描述，具体的数据直接通过 os cache 发送给网卡</p>\n",
            "tags": [
                "kafka"
            ]
        }
    ]
}