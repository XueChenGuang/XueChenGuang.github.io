{
    "version": "https://jsonfeed.org/version/1",
    "title": "该死的秋招 • All posts by \"kafka\" tag",
    "description": "孵化中···",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2023/10/12/kafka%E7%9B%B8%E5%85%B3/",
            "url": "http://example.com/2023/10/12/kafka%E7%9B%B8%E5%85%B3/",
            "title": "kafka相关",
            "date_published": "2023-10-12T13:06:00.000Z",
            "content_html": "<h3 id=\"写在前面\"><a class=\"markdownIt-Anchor\" href=\"#写在前面\">#</a> 写在前面</h3>\n<p>对于 kafka，没有使用经验，但是有的面试会问到，水也深，只能记一些理解的<br>\n先上图：<br>\n<img data-src=\"https://pic.imgdb.cn/item/6527f038c458853aef7b1fa7.jpg\" alt=\"\"></p>\n<h3 id=\"构成\"><a class=\"markdownIt-Anchor\" href=\"#构成\">#</a> 构成</h3>\n<p>简单聊一下构成，直接从大的来说，一个 kafka 服务器被称作一个 broker，若干个 broker 组成 kafka 集群；对于内部来说，broker 由若干个 topic 组成，每个 topic 包括若干个 partition，对于消费者来说，可以消费不同的 partition，所以可以支持批量消费，但是对于一个 partition 来说，消费者不能重复消费。</p>\n<h3 id=\"如何保证消费的有序\"><a class=\"markdownIt-Anchor\" href=\"#如何保证消费的有序\">#</a> 如何保证消费的有序</h3>\n<p>kafka 的 partition 中消息的存入是有序的，也就是链表的形式，所以要保证消费的有序，那么生产要生产到指定的分区，并且消费也针对具体的分区；或者就是只使用一个 partition。</p>\n<h3 id=\"如何防止重复消费\"><a class=\"markdownIt-Anchor\" href=\"#如何防止重复消费\">#</a> 如何防止重复消费</h3>\n<p>如果参数设置 auto-commit 为 true 的话，那么 offset 可能会提交不成功，那么就会导致重复消费；所以如果要防止重复消费，这个参数要设置成 false，具体的实现应该是 consumer 自主控制 offset。</p>\n<h3 id=\"如何保证消息不丢失\"><a class=\"markdownIt-Anchor\" href=\"#如何保证消息不丢失\">#</a> 如何保证消息不丢失</h3>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80NTk2MTA0MTg=\">https://zhuanlan.zhihu.com/p/459610418</span><br>\n 这篇写挺好的</p>\n",
            "tags": [
                "kafka"
            ]
        }
    ]
}