<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://example.com</id>
    <title>该死的秋招 • Posts by &#34;kafka&#34; tag</title>
    <link href="http://example.com" />
    <updated>2023-10-12T13:06:00.000Z</updated>
    <category term="hello blog" />
    <category term="设计模式" />
    <category term="MySQL" />
    <category term="算法" />
    <category term="Redis" />
    <category term="其他" />
    <category term="分布式" />
    <category term="数据结构" />
    <category term="Spring" />
    <category term="Thread" />
    <category term="Java" />
    <category term="JDK" />
    <category term="SQL" />
    <category term="JVM" />
    <category term="多线程" />
    <category term="kafka" />
    <category term="SpringBoot" />
    <category term="JUC相关零碎知识点乱写" />
    <category term="hashmap" />
    <category term="JUC" />
    <entry>
        <id>http://example.com/2023/10/12/kafka%E7%9B%B8%E5%85%B3/</id>
        <title>kafka相关</title>
        <link rel="alternate" href="http://example.com/2023/10/12/kafka%E7%9B%B8%E5%85%B3/"/>
        <content type="html">&lt;h3 id=&#34;写在前面&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#写在前面&#34;&gt;#&lt;/a&gt; 写在前面&lt;/h3&gt;
&lt;p&gt;对于 kafka，没有使用经验，但是有的面试会问到，水也深，只能记一些理解的&lt;br&gt;
先上图：&lt;br&gt;
&lt;img data-src=&#34;https://pic.imgdb.cn/item/6527f038c458853aef7b1fa7.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;构成&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#构成&#34;&gt;#&lt;/a&gt; 构成&lt;/h3&gt;
&lt;p&gt;简单聊一下构成，直接从大的来说，一个 kafka 服务器被称作一个 broker，若干个 broker 组成 kafka 集群；对于内部来说，broker 由若干个 topic 组成，每个 topic 包括若干个 partition，对于消费者来说，可以消费不同的 partition，所以可以支持批量消费，但是对于一个 partition 来说，消费者不能重复消费。&lt;/p&gt;
&lt;h3 id=&#34;如何保证消费的有序&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#如何保证消费的有序&#34;&gt;#&lt;/a&gt; 如何保证消费的有序&lt;/h3&gt;
&lt;p&gt;kafka 的 partition 中消息的存入是有序的，也就是链表的形式，所以要保证消费的有序，那么生产要生产到指定的分区，并且消费也针对具体的分区；或者就是只使用一个 partition。&lt;/p&gt;
&lt;h3 id=&#34;如何防止重复消费&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#如何防止重复消费&#34;&gt;#&lt;/a&gt; 如何防止重复消费&lt;/h3&gt;
&lt;p&gt;如果参数设置 auto-commit 为 true 的话，那么 offset 可能会提交不成功，那么就会导致重复消费；所以如果要防止重复消费，这个参数要设置成 false，具体的实现应该是 consumer 自主控制 offset。&lt;/p&gt;
&lt;h3 id=&#34;如何保证消息不丢失&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#如何保证消息不丢失&#34;&gt;#&lt;/a&gt; 如何保证消息不丢失&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80NTk2MTA0MTg=&#34;&gt;https://zhuanlan.zhihu.com/p/459610418&lt;/span&gt;&lt;br&gt;
 这篇写挺好的&lt;/p&gt;
&lt;h3 id=&#34;如何实现高效读写的&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#如何实现高效读写的&#34;&gt;#&lt;/a&gt; 如何实现高效读写的&lt;/h3&gt;
&lt;p&gt;页缓存 page cache（操作系统级的缓存） + 顺序写（通过末尾追加的方式写入数据） + 零拷贝（如果不做任何处理就是磁盘 - os cache - 应用缓存 - socket 缓存 - 网卡发送） 零拷贝就去掉了冗余的拷贝过程，直接让 socket 与网卡交互，socket 缓存了数据的描述，具体的数据直接通过 os cache 发送给网卡&lt;/p&gt;
</content>
        <category term="kafka" />
        <updated>2023-10-12T13:06:00.000Z</updated>
    </entry>
</feed>
