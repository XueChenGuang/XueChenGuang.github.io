<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://example.com</id>
    <title>该死的秋招 • Posts by &#34;kafka&#34; tag</title>
    <link href="http://example.com" />
    <updated>2023-10-12T13:06:00.000Z</updated>
    <category term="hello blog" />
    <category term="设计模式" />
    <category term="MySQL" />
    <category term="算法" />
    <category term="Redis" />
    <category term="其他" />
    <category term="分布式" />
    <category term="数据结构" />
    <category term="Spring" />
    <category term="Thread" />
    <category term="Java" />
    <category term="JDK" />
    <category term="SQL" />
    <category term="JVM" />
    <category term="多线程" />
    <category term="kafka" />
    <category term="SpringBoot" />
    <category term="JUC相关零碎知识点乱写" />
    <category term="hashmap" />
    <category term="JUC" />
    <category term="redis" />
    <category term="springboot" />
    <entry>
        <id>http://example.com/2023/10/12/kafka%E7%9B%B8%E5%85%B3/</id>
        <title>kafka相关</title>
        <link rel="alternate" href="http://example.com/2023/10/12/kafka%E7%9B%B8%E5%85%B3/"/>
        <content type="html">&lt;h3 id=&#34;写在前面&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#写在前面&#34;&gt;#&lt;/a&gt; 写在前面&lt;/h3&gt;
&lt;p&gt;对于 kafka，没有使用经验，但是有的面试会问到，水也深，只能记一些理解的&lt;br&gt;
先上图：&lt;br&gt;
&lt;img data-src=&#34;https://pic.imgdb.cn/item/6527f038c458853aef7b1fa7.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;构成&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#构成&#34;&gt;#&lt;/a&gt; 构成&lt;/h3&gt;
&lt;p&gt;简单聊一下构成，直接从大的来说，一个 kafka 服务器被称作一个 broker，若干个 broker 组成 kafka 集群；对于内部来说，broker 由若干个 topic 组成，每个 topic 包括若干个 partition，对于消费者来说，可以消费不同的 partition，所以可以支持批量消费，但是对于一个 partition 来说，消费者不能重复消费。&lt;/p&gt;
&lt;h3 id=&#34;如何保证消费的有序&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#如何保证消费的有序&#34;&gt;#&lt;/a&gt; 如何保证消费的有序&lt;/h3&gt;
&lt;p&gt;kafka 的 partition 中消息的存入是有序的，也就是链表的形式，所以要保证消费的有序，那么生产要生产到指定的分区，并且消费也针对具体的分区；或者就是只使用一个 partition。&lt;/p&gt;
&lt;h3 id=&#34;如何防止重复消费&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#如何防止重复消费&#34;&gt;#&lt;/a&gt; 如何防止重复消费&lt;/h3&gt;
&lt;p&gt;如果参数设置 auto-commit 为 true 的话，那么 offset 可能会提交不成功，那么就会导致重复消费；所以如果要防止重复消费，这个参数要设置成 false，具体的实现应该是 consumer 自主控制 offset。&lt;/p&gt;
&lt;h3 id=&#34;如何保证消息不丢失&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#如何保证消息不丢失&#34;&gt;#&lt;/a&gt; 如何保证消息不丢失&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80NTk2MTA0MTg=&#34;&gt;https://zhuanlan.zhihu.com/p/459610418&lt;/span&gt;&lt;br&gt;
 这篇写挺好的&lt;br&gt;
从三个方面来回答，producer 端，选用的同步策略默认是 1 对接 leader broker；0 发完就完事；all -1 等待所有的 follower；如果要保证发送端不丢的话就尽量增加接收的 follower 数，并且也要设置淘汰队列的最小数，也就是长时间未同步的副本会被踢出同步队列，这样全部踢完的话，那么 producer 端对接的 leader 挂掉的话，就会产生消息丢失了。&lt;/p&gt;
&lt;p&gt;broker 端，应为采用的页缓存，也就是 cpu 缓存，并且刷盘的策略是由操作系统完成的，所以这个时候就是会产生 broker 端挂掉，但是数据没刷盘的情况，所以保证 broker 端数据不丢的话，还是就是副本多完事&lt;/p&gt;
&lt;p&gt;consumer 端，导致的原因就是 offset 了，自动提交的话会导致业务挂了，但是 offset 后移了，那么就是消息丢失了，所以为了保证不丢，那么最好关掉 offset，并且先执行逻辑，然后提交 offset，这样就会出现重复消费的情况，那么可以选择加入幂等策略。&lt;/p&gt;
&lt;h3 id=&#34;如何实现高效读写的&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#如何实现高效读写的&#34;&gt;#&lt;/a&gt; 如何实现高效读写的&lt;/h3&gt;
&lt;p&gt;页缓存 page cache（操作系统级的缓存） + 顺序写（通过末尾追加的方式写入数据） + 零拷贝（如果不做任何处理就是磁盘 - os cache - 应用缓存 - socket 缓存 - 网卡发送） 零拷贝就去掉了冗余的拷贝过程，直接让 socket 与网卡交互，socket 缓存了数据的描述，具体的数据直接通过 os cache 发送给网卡&lt;/p&gt;
</content>
        <category term="kafka" />
        <updated>2023-10-12T13:06:00.000Z</updated>
    </entry>
</feed>
